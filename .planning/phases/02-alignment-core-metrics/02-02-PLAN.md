---
phase: 02-alignment-core-metrics
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - js/stt-api.js
  - js/recorder.js
  - js/file-handler.js
  - js/ui.js
  - js/app.js
  - index.html
  - style.css
autonomous: false

must_haves:
  truths:
    - "After recording, each reference word is displayed color-coded: green=correct, orange=substitution, red=omission"
    - "Insertions are shown separately in blue below the reference words"
    - "WCPM and accuracy percentage are displayed after assessment"
    - "A timer is visible during recording that tracks assessment duration"
    - "The full pipeline runs: STT -> alignment -> metrics -> color-coded display"
  artifacts:
    - path: "js/stt-api.js"
      provides: "sendToSTT returns STT data instead of calling displayResults"
      exports: ["sendToSTT"]
    - path: "js/ui.js"
      provides: "displayAlignmentResults renders color-coded words and metrics"
      exports: ["setStatus", "displayResults", "displayAlignmentResults"]
    - path: "js/app.js"
      provides: "Pipeline orchestration: STT -> align -> metrics -> display"
  key_links:
    - from: "js/recorder.js"
      to: "js/app.js"
      via: "Calls pipeline function instead of sendToSTT directly"
      pattern: "processAudio|runPipeline"
    - from: "js/app.js"
      to: "js/alignment.js"
      via: "import alignWords"
      pattern: "import.*alignWords.*from.*alignment"
    - from: "js/app.js"
      to: "js/metrics.js"
      via: "import computeWCPM, computeAccuracy"
      pattern: "import.*from.*metrics"
    - from: "js/ui.js"
      to: "DOM"
      via: "Color-coded word spans with CSS classes"
      pattern: "word-correct|word-substitution|word-omission|word-insertion"
---

<objective>
Refactor the data flow so STT returns data (not displays it), wire the full pipeline (STT -> alignment -> metrics -> display), update the UI to show color-coded word classifications and metrics.

Purpose: This completes Phase 2 by connecting the alignment engine to the actual app flow and giving users visible feedback.
Output: Working end-to-end pipeline with color-coded results, WCPM, and accuracy display.
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-alignment-core-metrics/02-01-SUMMARY.md
@js/stt-api.js
@js/recorder.js
@js/file-handler.js
@js/ui.js
@js/app.js
@index.html
@style.css
@js/alignment.js
@js/metrics.js
@js/text-normalize.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor sendToSTT and wire pipeline in app.js</name>
  <files>js/stt-api.js, js/recorder.js, js/file-handler.js, js/app.js</files>
  <action>
  1. Refactor `js/stt-api.js`:
  - Remove import of displayResults from ui.js (keep setStatus import)
  - Change sendToSTT to RETURN the parsed data object instead of calling displayResults
  - On success: `return data;` instead of `displayResults(data); setStatus('Done.');`
  - On error (API error or fetch failure): still call setStatus, but also `return null;`
  - The function signature stays the same: `async function sendToSTT(blob, encoding)`

  2. Create pipeline function in `js/app.js`:
  - Import alignWords from alignment.js
  - Import computeWCPM, computeAccuracy from metrics.js
  - Import sendToSTT from stt-api.js
  - Import displayResults, displayAlignmentResults (new, from ui.js), setStatus from ui.js
  - Export a function `processAssessment(blob, encoding)` that:
    a. Records start time: `const startTime = Date.now();`
    b. Calls `const data = await sendToSTT(blob, encoding);`
    c. If !data or !data.results, call displayResults(data) for backward compat (shows "No speech detected") and return
    d. Gets reference text from `document.getElementById('transcript').value.trim()`
    e. If no reference text, fall back to displayResults(data) (raw transcript display) and setStatus('Done (no reference passage for alignment).') and return
    f. Extracts transcript words from data: flatten all data.results[].alternatives[0].words into single array
    g. Calls `const alignment = alignWords(referenceText, transcriptWords);`
    h. Computes elapsed seconds: `(Date.now() - startTime) / 1000` -- BUT actually use the recorder's timer seconds, not Date.now. Pass elapsedSeconds as a parameter to processAssessment: `processAssessment(blob, encoding, elapsedSeconds)`
    i. Calls `const wcpm = computeWCPM(alignment, elapsedSeconds);`
    j. Calls `const accuracy = computeAccuracy(alignment);`
    k. Calls `displayAlignmentResults(alignment, wcpm, accuracy);`
    l. Calls `setStatus('Done.');`

  3. Update `js/recorder.js`:
  - Instead of calling sendToSTT directly in mediaRecorder.onstop, call the pipeline function
  - Import processAssessment from app.js (or have app.js register a callback)
  - SIMPLER APPROACH: Have recorder.js export an onRecordingComplete callback setter, and app.js sets it during init. This avoids circular imports.
  - In recorder.js: `let onComplete = null; export function setOnComplete(fn) { onComplete = fn; }`
  - In onstop: `if (onComplete) onComplete(blob, 'WEBM_OPUS', seconds);`
  - Keep the existing timer (seconds variable) -- pass it as the third argument

  4. Update `js/file-handler.js`:
  - Same pattern: export setOnComplete, call it instead of sendToSTT directly
  - For file uploads, elapsedSeconds is unknown (file was pre-recorded). Pass 0 or null.
  - In processAssessment, if elapsedSeconds is 0/null/undefined, skip WCPM calculation (display "N/A" for WCPM)

  5. In `js/app.js` init:
  - Import setOnComplete from recorder.js and file-handler.js
  - Set both to call processAssessment
  - `recorderSetOnComplete((blob, enc, secs) => processAssessment(blob, enc, secs));`
  - `fileHandlerSetOnComplete((blob, enc) => processAssessment(blob, enc, null));`
  </action>
  <verify>
  - App loads without console errors
  - Recording still works (Record button -> Stop -> sends to STT)
  - File upload still works
  - If no reference text: shows raw transcript as before
  - If reference text present: processAssessment runs full pipeline (check console for any errors)
  </verify>
  <done>
  - sendToSTT returns data instead of displaying
  - recorder.js and file-handler.js use callback pattern (no circular imports)
  - app.js orchestrates: STT -> alignment -> metrics -> display
  - Elapsed seconds passed from recorder timer
  - File uploads pass null for elapsed (WCPM shows N/A)
  </done>
</task>

<task type="auto">
  <name>Task 2: Update UI for color-coded alignment results and metrics display</name>
  <files>js/ui.js, index.html, style.css</files>
  <action>
  1. Add `displayAlignmentResults(alignment, wcpm, accuracy)` to `js/ui.js`:
  - Clear resultWords div
  - Create a metrics summary bar above words showing:
    - WCPM value (or "N/A" if wcpm is null): bold number with label
    - Accuracy percentage: bold number with label
    - Error counts: "X substitutions, Y omissions, Z insertions"
  - Render reference words as spans with CSS classes:
    - type "correct": class "word-correct" (green background)
    - type "substitution": class "word-substitution" (orange background), show tooltip with "Expected: {ref}, Said: {hyp}"
    - type "omission": class "word-omission" (red background, strikethrough), show the ref word
    - Skip insertions in the main word flow
  - After reference words, add a separate "Insertions" section (only if insertions exist):
    - Label: "Inserted words (not in passage):"
    - Show each insertion word with class "word-insertion" (blue background)
  - Keep displayResults() for backward compatibility (raw STT display when no reference)
  - Put metrics in resultPlain div area. Put alignment words in resultWords div. Put raw JSON in resultJson div (stringify alignment + metrics).

  2. Update `index.html`:
  - Update the legend div to show alignment colors instead of confidence colors:
    - `<span class="word-correct">Correct</span> <span class="word-substitution">Substitution</span> <span class="word-omission">Omission</span> <span class="word-insertion">Insertion</span>`
  - Keep the existing result sections (resultWords, resultPlain, resultJson)

  3. Update `style.css`:
  - Add classes: .word-correct (green bg #c8e6c9, dark green text), .word-substitution (orange bg #ffe0b2, dark orange text), .word-omission (red bg #ffcdd2, text-decoration line-through), .word-insertion (blue bg #bbdefb, dark blue text)
  - Style the metrics summary: flexbox row, each metric in a card-like box with padding
  - Keep existing .high/.mid/.low classes (still used for raw display mode)
  </action>
  <verify>
  - Load app in browser
  - Enter reference text: "The big dog ran fast"
  - Record audio saying "The dig ran fast slowly"
  - After STT returns, verify:
    - "The" shows green (correct)
    - "big" shows orange with tooltip (substitution -> dig)
    - "dog" shows red strikethrough (omission)
    - "ran" shows green (correct)
    - "fast" shows green (correct)
    - "slowly" shows in blue insertion section
    - Metrics bar shows WCPM, accuracy %, error counts
  </verify>
  <done>
  - Color-coded word display works for all 4 classification types
  - Metrics summary (WCPM, accuracy, error breakdown) visible after assessment
  - Insertions shown separately
  - Legend updated to show alignment colors
  - Raw display mode still works when no reference text
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Phase 2 pipeline: STT transcript aligned against reference text with color-coded word display, WCPM, and accuracy metrics</what-built>
  <how-to-verify>
  1. Open the app in browser
  2. Enter API key
  3. Type reference passage: "The big brown fox jumped over the lazy dog"
  4. Click Record and read: "The big brown fox jumped over the lazy dog" (read it correctly)
  5. Verify: all words green, WCPM shown, accuracy ~100%
  6. Try again with deliberate errors: skip "brown", say "hopped" instead of "jumped", add "quickly" at end
  7. Verify: "brown" red (omission), "jumped" orange (substitution showing "hopped"), "quickly" blue (insertion)
  8. Verify WCPM and accuracy reflect errors
  9. Try with NO reference text -- should show raw transcript (backward compat)
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
- Full pipeline: Record -> STT -> Alignment -> Metrics -> Color-coded display
- All 4 word types visually distinct (correct=green, substitution=orange, omission=red, insertion=blue)
- WCPM and accuracy displayed with correct values
- Timer tracks recording duration, used for WCPM calculation
- Backward compatible: no reference text = raw transcript display
- File upload still works (WCPM shows N/A)
</verification>

<success_criteria>
- Phase 2 success criteria 1-5 from roadmap are all met
- Each reference word marked as correct/substitution/omission/insertion
- WCPM calculated and displayed
- Accuracy percentage displayed
- Timer visible during reading
- Insertions identified and shown separately
</success_criteria>

<output>
After completion, create `.planning/phases/02-alignment-core-metrics/02-02-SUMMARY.md`
</output>
