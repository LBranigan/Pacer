---
phase: 02-alignment-core-metrics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - js/text-normalize.js
  - js/alignment.js
autonomous: true

must_haves:
  truths:
    - "normalizeText lowercases and strips punctuation but keeps apostrophes and hyphens"
    - "alignWords returns array of {ref, hyp, type} where type is correct|substitution|omission|insertion"
    - "Adjacent DELETE+INSERT pairs are merged into substitutions"
    - "Disfluencies (um, uh, uh-huh) are filtered from transcript before alignment"
  artifacts:
    - path: "js/text-normalize.js"
      provides: "normalizeText, filterDisfluencies"
      exports: ["normalizeText", "filterDisfluencies"]
    - path: "js/alignment.js"
      provides: "Word-level diff alignment using diff-match-patch word encoding"
      exports: ["alignWords"]
  key_links:
    - from: "js/alignment.js"
      to: "js/text-normalize.js"
      via: "import normalizeText, filterDisfluencies"
      pattern: "import.*from.*text-normalize"
    - from: "js/alignment.js"
      to: "diff_match_patch CDN"
      via: "Uses globally loaded diff_match_patch"
      pattern: "new diff_match_patch|dmp"
---

<objective>
Create the text normalization utility and word-level alignment engine that diffs STT transcript against reference text.

Purpose: This is the core algorithm of the entire app -- without alignment, no word classification or metrics are possible.
Output: Two pure-logic modules: text-normalize.js (normalization + disfluency filtering) and alignment.js (word-level diff producing classified word array).
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-alignment-core-metrics/02-RESEARCH.md
@js/stt-api.js
@index.html
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create text-normalize.js and alignment.js</name>
  <files>js/text-normalize.js, js/alignment.js, index.html</files>
  <action>
  1. Create `js/text-normalize.js` with two exported functions:

  `normalizeText(text)` -- takes a string, returns array of lowercase words with punctuation stripped EXCEPT apostrophes and hyphens within words. Remove leading/trailing punctuation from each word. Filter empty strings.
  Example: "The dog's BALL, ran--fast!" -> ["the", "dog's", "ball", "ran--fast"]

  `filterDisfluencies(words)` -- takes array of word strings, removes common disfluencies: "um", "uh", "uh-huh", "mm", "hmm", "er", "ah". Returns filtered array.

  2. Create `js/alignment.js` with one exported function:

  `alignWords(referenceText, transcriptWords)` -- takes reference text string and array of STT word objects (each has `.word` property at minimum).

  Implementation approach (from RESEARCH.md -- word-level diff via character encoding):
  - Normalize reference text via normalizeText() to get refWords array
  - Extract transcript words from STT word objects, normalize each, filter disfluencies
  - Encode: assign each unique word a Unicode character. Build two encoded strings (one for ref, one for hyp).
  - Use diff_match_patch (loaded globally via CDN script tag) to diff the two encoded strings.
  - Decode diff results back to word classifications:
    - EQUAL = "correct"
    - DELETE (ref word not in transcript) = "omission"
    - INSERT (transcript word not in ref) = "insertion"
    - Adjacent DELETE immediately followed by INSERT = "substitution" (merge them: use the ref word as `ref` and hyp word as `hyp`)
  - Return array of objects: `{ ref: string|null, hyp: string|null, type: "correct"|"substitution"|"omission"|"insertion" }`
    - correct: { ref: "the", hyp: "the", type: "correct" }
    - substitution: { ref: "dog", hyp: "dig", type: "substitution" }
    - omission: { ref: "big", hyp: null, type: "omission" }
    - insertion: { ref: null, hyp: "um", type: "insertion" } (note: disfluencies should already be filtered, but other insertions remain)

  3. Add diff-match-patch CDN script tag to `index.html` BEFORE the app.js module script:
  `<script src="https://cdnjs.cloudflare.com/ajax/libs/diff_match_patch/20121119/diff_match_patch.js"></script>`

  IMPORTANT: diff_match_patch is loaded as a global. In alignment.js, instantiate with `const dmp = new diff_match_patch();` (the class is on window).

  IMPORTANT: The substitution merge logic must handle the case where a DELETE chunk has multiple words followed by an INSERT chunk with multiple words. Pair them 1:1 left-to-right; any excess DELETE words become omissions, excess INSERT words become insertions.
  </action>
  <verify>
  Open browser dev console on index.html. Run:
  ```js
  import('/js/text-normalize.js').then(m => {
    console.log(m.normalizeText("The DOG's ball, ran!"));
    console.log(m.filterDisfluencies(["the", "um", "dog", "uh"]));
  });
  ```
  Expected: ["the", "dog's", "ball", "ran"] and ["the", "dog"]

  Then test alignment:
  ```js
  import('/js/alignment.js').then(m => {
    const result = m.alignWords("The big dog ran fast", [
      {word: "The"}, {word: "dig"}, {word: "ran"}, {word: "um"}, {word: "fast"}, {word: "slowly"}
    ]);
    console.log(JSON.stringify(result, null, 2));
  });
  ```
  Expected: correct(the), substitution(big->dig), omission(dog), correct(ran), correct(fast), insertion(slowly)
  </verify>
  <done>
  - normalizeText strips punctuation, lowercases, preserves apostrophes/hyphens
  - filterDisfluencies removes um/uh/etc
  - alignWords produces correct/substitution/omission/insertion classifications
  - Adjacent DELETE+INSERT merged into substitutions with 1:1 pairing
  - diff-match-patch loaded via CDN in index.html
  </done>
</task>

<task type="auto">
  <name>Task 2: Create metrics.js</name>
  <files>js/metrics.js</files>
  <action>
  Create `js/metrics.js` with two exported functions:

  `computeWCPM(alignmentResult, elapsedSeconds)` -- takes alignment array (from alignWords) and duration in seconds.
  - Count words where type === "correct" (these are words read correctly)
  - WCPM = (correctCount / elapsedSeconds) * 60
  - Return { wcpm: number (rounded to 1 decimal), correctCount: number, elapsedSeconds: number }
  - If elapsedSeconds <= 0, return wcpm: 0

  `computeAccuracy(alignmentResult)` -- takes alignment array.
  - totalRefWords = count of items where type is "correct", "substitution", or "omission" (i.e., words that exist in reference)
  - correctCount = count where type === "correct"
  - accuracy = (correctCount / totalRefWords) * 100
  - Also count: substitutions, omissions, insertions
  - Return { accuracy: number (rounded to 1 decimal), correctCount, totalRefWords, substitutions, omissions, insertions }
  - If totalRefWords === 0, return accuracy: 0

  NOTE: Insertions are NOT counted as errors per ORF standard. Errors = substitutions + omissions only. WCPM uses correct words only (not total minus errors, which would give the same result but is less clear).
  </action>
  <verify>
  Browser console test:
  ```js
  import('/js/metrics.js').then(m => {
    const alignment = [
      {ref:"the", hyp:"the", type:"correct"},
      {ref:"big", hyp:"dig", type:"substitution"},
      {ref:"dog", hyp:null, type:"omission"},
      {ref:"ran", hyp:"ran", type:"correct"},
      {ref:null, hyp:"slowly", type:"insertion"}
    ];
    console.log(m.computeWCPM(alignment, 30));
    console.log(m.computeAccuracy(alignment));
  });
  ```
  Expected WCPM: { wcpm: 4.0, correctCount: 2, elapsedSeconds: 30 }
  Expected Accuracy: { accuracy: 50.0, correctCount: 2, totalRefWords: 4, substitutions: 1, omissions: 1, insertions: 1 }
  </verify>
  <done>
  - computeWCPM returns correct WCPM calculation
  - computeAccuracy returns accuracy percentage and error breakdown
  - Insertions excluded from error count and total ref words
  </done>
</task>

</tasks>

<verification>
- All three JS files exist and export their functions
- diff-match-patch CDN script tag present in index.html
- No existing functionality broken (app still loads, record/upload still works)
- Console import tests pass for all exported functions
</verification>

<success_criteria>
- normalizeText, filterDisfluencies, alignWords, computeWCPM, computeAccuracy all work as pure functions
- Alignment correctly classifies words as correct/substitution/omission/insertion
- WCPM and accuracy calculations match ORF standards
</success_criteria>

<output>
After completion, create `.planning/phases/02-alignment-core-metrics/02-01-SUMMARY.md`
</output>
