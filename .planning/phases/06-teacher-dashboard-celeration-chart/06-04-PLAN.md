---
phase: 06-teacher-dashboard-celeration-chart
plan: 04
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - js/audio-playback.js
  - js/dashboard.js
  - index.html
  - style.css
autonomous: false

must_haves:
  truths:
    - "Teacher can play back student audio from a saved assessment"
    - "Words highlight one-by-one in sync with audio playback using STT timestamps"
    - "Playback has play/pause controls and a progress indicator"
  artifacts:
    - path: "js/audio-playback.js"
      provides: "Word-synced audio playback engine"
      exports: ["createSyncedPlayback"]
      min_lines: 40
  key_links:
    - from: "js/audio-playback.js"
      to: "js/audio-store.js"
      via: "import getAudioBlob"
      pattern: "getAudioBlob"
    - from: "js/dashboard.js"
      to: "js/audio-playback.js"
      via: "import createSyncedPlayback"
      pattern: "createSyncedPlayback"
---

<objective>
Add word-synced audio playback to the teacher dashboard so teachers can replay a student's reading with word-by-word highlighting.

Purpose: Satisfies TCHR-05 -- teacher can review exactly how a student read, seeing which words were spoken when.
Output: audio-playback.js module, playback UI integrated into dashboard assessment detail view.
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-teacher-dashboard-celeration-chart/06-RESEARCH.md
@.planning/phases/06-teacher-dashboard-celeration-chart/06-01-SUMMARY.md
@js/audio-store.js
@js/dashboard.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create audio-playback.js with word-synced highlighting</name>
  <files>js/audio-playback.js</files>
  <action>
Create `js/audio-playback.js` as an ES module:

Import `getAudioBlob` from `./audio-store.js`.

Export `createSyncedPlayback(containerEl)` factory function that returns `{ load(assessmentId, sttWords, alignment), play(), pause(), destroy() }`:

1. **Internal state**: audioEl (HTMLAudioElement), wordEls (array of span elements), sttWords, animFrameId, isPlaying

2. **load(assessmentId, sttWords, alignment)**:
   - Fetch audio blob via `getAudioBlob(assessmentId)`
   - If no blob, show "Audio not available" message in container
   - Create object URL from blob, set as audioEl.src
   - Render the alignment words as spans inside containerEl:
     - For each alignment entry, create a `<span class="playback-word {type}">` where type is correct/substitution/omission/insertion
     - For substitutions: show both ref and hyp words (e.g., "expected(spoke)")
     - For omissions: show the missed word with strikethrough style
     - Store reference to span elements in wordEls array
   - Map each word span to its corresponding STT timestamp (match by position/index, handling omissions which have no STT entry)

3. **Sync loop** (requestAnimationFrame):
   - On each frame, get `audioEl.currentTime`
   - For each word span with an associated STT timestamp:
     - Parse startTime and endTime (handle "Xs" format: `parseFloat(t.replace('s',''))`)
     - If currentTime >= start && currentTime < end: add `.speaking` class
     - Otherwise: remove `.speaking` class
   - If audioEl is paused or ended, cancel animation frame

4. **play()**: audioEl.play(), start sync loop
5. **pause()**: audioEl.pause()
6. **destroy()**: pause, revoke object URL, clear container, cancel animation frame

7. **UI elements created inside containerEl**:
   - Play/pause button
   - Audio progress bar (use audioEl timeupdate event to update a range input or progress element)
   - Current time / duration display
   - The word display area with highlighting
  </action>
  <verify>
1. `import { createSyncedPlayback } from './js/audio-playback.js'` resolves without error
2. Module has no side effects on import
  </verify>
  <done>audio-playback.js exports createSyncedPlayback with load/play/pause/destroy API. Words render with type-based styling. requestAnimationFrame sync loop highlights active word based on audio.currentTime vs STT timestamps.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate audio playback into dashboard assessment detail</name>
  <files>js/dashboard.js, index.html, style.css</files>
  <action>
In `js/dashboard.js`:
1. Import `createSyncedPlayback` from `./audio-playback.js`
2. In the assessment card click handler, after rendering error breakdown:
   - If the selected assessment has `audioRef` and `sttWords`, show a "Play Audio" section
   - Create a div id="audioPlaybackArea" inside the error breakdown area (or adjacent)
   - Initialize synced playback: `const playback = createSyncedPlayback(audioPlaybackArea)`
   - Call `playback.load(assessment.audioRef, assessment.sttWords, assessment.alignment)`
   - When switching to a different assessment card, call `playback.destroy()` first
   - If assessment has no audioRef, show "Audio not recorded for this assessment"

In `index.html`:
- Ensure the dashboardSection has a div placeholder for audio playback (or let dashboard.js create it dynamically)

In `style.css`:
- `.playback-word` base style (inline-block, padding, margin, border-radius for pill shape)
- `.playback-word.correct` default color
- `.playback-word.substitution` red background tint
- `.playback-word.omission` orange with strikethrough
- `.playback-word.insertion` blue background tint
- `.playback-word.speaking` bright highlight (yellow background or ring animation) to indicate current word
- `.playback-controls` flexbox for play/pause button and progress bar
- Smooth transition on `.speaking` class (transition: background-color 0.1s)
  </action>
  <verify>
1. Open app, run an assessment with a student selected (to generate audio + sttWords)
2. Open dashboard, click the assessment card
3. "Play Audio" section should appear with word display
4. Click play -- audio plays and words highlight in sequence
5. Words styled by type (correct=default, substitution=red, omission=strikethrough)
6. Currently-spoken word has bright highlight that moves through the text
  </verify>
  <done>Audio playback integrated into dashboard. Teacher can click any assessment with audio, play it back, and see words highlight in real-time synced to STT timestamps.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Word-synced audio playback in the teacher dashboard. When viewing an assessment, teacher can play the student's audio and see each word highlight as it's spoken.</what-built>
  <how-to-verify>
1. Run a new assessment with a student selected (record yourself reading a short passage)
2. Open the dashboard for that student
3. Click the most recent assessment card
4. Verify the "Play Audio" section appears with the passage words displayed
5. Click play -- verify audio plays and words highlight one by one in sync
6. Verify substitutions show in red, omissions in orange/strikethrough
7. Pause and resume -- verify sync resumes correctly
8. Click a different assessment -- verify previous playback stops cleanly
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
1. Audio loads from IndexedDB and plays back
2. Words highlight in sync with audio using STT timestamps
3. Play/pause controls work
4. Different error types visually distinguishable during playback
5. Switching assessments cleans up previous playback
</verification>

<success_criteria>
- TCHR-05: Teacher can play student audio with word-by-word highlighting
- Highlighting is synced to STT timestamps via requestAnimationFrame
- Error types visually coded during playback
- No audio/memory leaks on navigation
</success_criteria>

<output>
After completion, create `.planning/phases/06-teacher-dashboard-celeration-chart/06-04-SUMMARY.md`
</output>
