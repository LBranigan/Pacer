---
phase: 20-reverb-backend-service
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - services/reverb/requirements.txt
  - services/reverb/Dockerfile
  - services/reverb/docker-compose.yml
autonomous: true

must_haves:
  truths:
    - "Docker build completes without errors"
    - "Container image includes PyTorch with CUDA support"
    - "GPU reservation declared in docker-compose"
  artifacts:
    - path: "services/reverb/requirements.txt"
      provides: "Python dependencies for Reverb service"
      contains: "rev-reverb"
    - path: "services/reverb/Dockerfile"
      provides: "Container definition with CUDA base"
      contains: "pytorch/pytorch"
    - path: "services/reverb/docker-compose.yml"
      provides: "GPU orchestration config"
      contains: "capabilities: [gpu]"
  key_links:
    - from: "docker-compose.yml"
      to: "Dockerfile"
      via: "build context"
      pattern: "build:"
---

<objective>
Create the Docker infrastructure for Reverb ASR service with GPU support.

Purpose: Establishes the container foundation that the FastAPI server will run in. GPU access must be configured correctly before writing the Python service.

Output: Buildable Docker image with PyTorch+CUDA, GPU reservation in compose, ready for server.py in Plan 02.
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/20-reverb-backend-service/20-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create service directory and requirements.txt</name>
  <files>services/reverb/requirements.txt</files>
  <action>
Create the services/reverb/ directory structure.

Create requirements.txt with exact versions from research:
```
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
python-multipart>=0.0.9
rev-reverb==0.1.0
```

Note: PyTorch is installed by rev-reverb dependency, do NOT add it manually.
  </action>
  <verify>cat services/reverb/requirements.txt shows all 4 dependencies</verify>
  <done>requirements.txt exists with fastapi, uvicorn, python-multipart, rev-reverb</done>
</task>

<task type="auto">
  <name>Task 2: Create Dockerfile with CUDA base</name>
  <files>services/reverb/Dockerfile</files>
  <action>
Create Dockerfile with pytorch/pytorch:2.4.0-cuda11.8-cudnn9-runtime base image.

Include:
1. System dependencies: ffmpeg, git, git-lfs, libsndfile1 (required by reverb)
2. git lfs install (required for model download)
3. WORKDIR /app
4. Copy and install requirements.txt
5. Install rev-reverb==0.1.0 (separate layer for caching)
6. Copy server.py (will exist after Plan 02)
7. EXPOSE 8765
8. CMD for uvicorn with host 0.0.0.0 and port 8765

IMPORTANT: Do NOT pre-download model in Dockerfile (causes HuggingFace auth issues in some environments). Model downloads at first request.
  </action>
  <verify>cat services/reverb/Dockerfile shows FROM pytorch/pytorch:2.4.0-cuda11.8-cudnn9-runtime</verify>
  <done>Dockerfile exists with CUDA base image, system deps, Python deps, and uvicorn CMD</done>
</task>

<task type="auto">
  <name>Task 3: Create docker-compose.yml with GPU reservation</name>
  <files>services/reverb/docker-compose.yml</files>
  <action>
Create docker-compose.yml with GPU support using modern syntax:

```yaml
version: '3.8'
services:
  reverb:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8765:8765"
    volumes:
      - reverb-cache:/root/.cache  # Persist model cache
    environment:
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

volumes:
  reverb-cache:
```

Critical: The deploy.resources.reservations.devices section is what enables GPU access. Without this, container runs on CPU silently.
  </action>
  <verify>grep -A5 "reservations" services/reverb/docker-compose.yml shows nvidia device reservation</verify>
  <done>docker-compose.yml exists with GPU reservation, port 8765, and model cache volume</done>
</task>

</tasks>

<verification>
Requirements coverage:
- BACK-01 (partial): Docker container defined with GPU access configured

All three files exist and are syntactically valid:
```bash
cd services/reverb && ls -la
cat requirements.txt
head -20 Dockerfile
cat docker-compose.yml
```

Note: Full BACK-01 verification (container actually runs with GPU) happens in Plan 02 after server.py exists.
</verification>

<success_criteria>
1. services/reverb/ directory exists
2. requirements.txt contains fastapi, uvicorn, python-multipart, rev-reverb
3. Dockerfile uses pytorch/pytorch:2.4.0-cuda11.8-cudnn9-runtime base
4. docker-compose.yml has GPU reservation with nvidia driver
5. All files are syntactically valid YAML/Dockerfile format
</success_criteria>

<output>
After completion, create `.planning/phases/20-reverb-backend-service/20-01-SUMMARY.md`
</output>
