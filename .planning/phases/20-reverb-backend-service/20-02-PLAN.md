---
phase: 20-reverb-backend-service
plan: 02
type: execute
wave: 2
depends_on: ["20-01"]
files_modified:
  - services/reverb/server.py
autonomous: false

must_haves:
  truths:
    - "Service starts with GPU verification at startup"
    - "Health endpoint returns GPU info and model status"
    - "Ensemble endpoint returns both verbatim and clean transcripts"
    - "Browser can call endpoints (CORS works)"
  artifacts:
    - path: "services/reverb/server.py"
      provides: "FastAPI server with health and ensemble endpoints"
      exports: ["app"]
      min_lines: 100
  key_links:
    - from: "server.py startup"
      to: "torch.cuda.is_available()"
      via: "startup event"
      pattern: "torch\\.cuda\\.is_available"
    - from: "/ensemble endpoint"
      to: "wenet.load_model"
      via: "model singleton"
      pattern: "wenet\\.load_model"
    - from: "/ensemble endpoint"
      to: "parse_ctm function"
      via: "CTM output processing"
      pattern: "parse_ctm"
---

<objective>
Implement the FastAPI server with health and ensemble endpoints, then verify browser access.

Purpose: Creates the actual service that browsers will call for Reverb ASR transcription. This completes all BACK-* requirements.

Output: Running Reverb service accessible from browser with GPU acceleration verified.
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/20-reverb-backend-service/20-RESEARCH.md
@.planning/phases/20-reverb-backend-service/20-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create server.py with health endpoint and GPU verification</name>
  <files>services/reverb/server.py</files>
  <action>
Create server.py with FastAPI application structure:

1. **Imports**: FastAPI, CORSMiddleware, BaseModel, asyncio, base64, tempfile, os, torch, wenet

2. **CORS Configuration** (critical for browser access):
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost",
        "http://localhost:8080",
        "http://127.0.0.1",
        "http://127.0.0.1:8080",
        "null",  # file:// protocol sends "null" as origin
    ],
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["Content-Type"],
)
```

3. **GPU Lock**: `gpu_lock = asyncio.Lock()` for VRAM protection

4. **Model Singleton**:
```python
_model = None
def get_model():
    global _model
    if _model is None:
        _model = wenet.load_model("reverb_asr_v1")
    return _model
```

5. **Startup Event** (BACK-04):
```python
@app.on_event("startup")
async def startup():
    if not torch.cuda.is_available():
        raise RuntimeError(
            "GPU not available - check Docker --gpus flag and NVIDIA Container Toolkit"
        )
    device_name = torch.cuda.get_device_name(0)
    vram_mb = torch.cuda.get_device_properties(0).total_memory / 1024 / 1024
    print(f"[reverb] GPU verified: {device_name} ({vram_mb:.0f}MB)")
    # Do NOT pre-load model here - let first request trigger load
```

6. **Health Endpoint** (BACK-03):
```python
@app.get("/health")
async def health():
    gpu_info = None
    if torch.cuda.is_available():
        gpu_info = {
            "name": torch.cuda.get_device_name(0),
            "memory_mb": torch.cuda.get_device_properties(0).total_memory // 1024 // 1024,
            "memory_used_mb": torch.cuda.memory_allocated(0) // 1024 // 1024
        }
    return {
        "status": "ok" if _model else "ready",
        "model_loaded": _model is not None,
        "gpu": gpu_info
    }
```
  </action>
  <verify>grep -c "torch.cuda.is_available" services/reverb/server.py returns 2 (startup + health)</verify>
  <done>server.py has FastAPI app with CORS, GPU lock, model singleton, startup verification, and health endpoint</done>
</task>

<task type="auto">
  <name>Task 2: Add CTM parser and ensemble endpoint</name>
  <files>services/reverb/server.py</files>
  <action>
Add to server.py:

1. **Filler words set** for confidence defaults:
```python
FILLERS = {'um', 'uh', 'er', 'ah', 'mm', 'hmm', 'hm'}
```

2. **CTM Parser** (BACK-05):
```python
def parse_ctm(ctm_text: str) -> list:
    """
    CTM format: <file> <channel> <start> <duration> <word> [<confidence>]
    Phase 0 verified: 6 fields present but confidence always 0.00
    Use type-based defaults instead.
    """
    words = []
    for line in ctm_text.strip().split('\n'):
        if not line.strip():
            continue
        parts = line.split()
        if len(parts) < 5:
            continue

        word_text = parts[4]
        start = float(parts[2])
        duration = float(parts[3])

        # Default confidence: 0.7 for fillers, 0.9 for content words
        conf = 0.7 if word_text.lower() in FILLERS else 0.9

        words.append({
            "word": word_text,
            "start_time": start,
            "end_time": start + duration,
            "confidence": conf
        })
    return words
```

3. **Pydantic models**:
```python
class EnsembleRequest(BaseModel):
    audio_base64: str

class Word(BaseModel):
    word: str
    start_time: float
    end_time: float
    confidence: float
```

4. **Ensemble Endpoint** (BACK-02):
```python
@app.post("/ensemble")
async def ensemble(req: EnsembleRequest):
    # Decode base64 audio
    try:
        audio = base64.b64decode(req.audio_base64)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid base64: {e}")

    async with gpu_lock:
        # Write to temp file
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            f.write(audio)
            temp_path = f.name

        try:
            model = get_model()

            # Pass 1: Verbatim (v=1.0) - preserves disfluencies
            verbatim_ctm = model.transcribe(temp_path, verbatimicity=1.0, format="ctm")
            verbatim_words = parse_ctm(verbatim_ctm)

            # Pass 2: Clean (v=0.0) - removes disfluencies
            clean_ctm = model.transcribe(temp_path, verbatimicity=0.0, format="ctm")
            clean_words = parse_ctm(clean_ctm)

            # Clear GPU memory after processing
            torch.cuda.empty_cache()

            return {
                "verbatim": {
                    "words": verbatim_words,
                    "transcript": " ".join(w["word"] for w in verbatim_words),
                    "verbatimicity": 1.0
                },
                "clean": {
                    "words": clean_words,
                    "transcript": " ".join(w["word"] for w in clean_words),
                    "verbatimicity": 0.0
                }
            }
        finally:
            os.unlink(temp_path)
```

Add HTTPException import at top: `from fastapi import FastAPI, HTTPException`
  </action>
  <verify>grep -c "def parse_ctm" services/reverb/server.py returns 1 AND grep -c "@app.post" services/reverb/server.py returns 1</verify>
  <done>server.py has CTM parser with type-based confidence defaults and ensemble endpoint returning both v=1.0 and v=0.0</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Build and verify service from browser</name>
  <what-built>
Complete Reverb ASR service with:
- Docker container with GPU access
- /health endpoint returning GPU status
- /ensemble endpoint returning dual transcripts
- CORS configured for browser access
  </what-built>
  <how-to-verify>
1. Build and start the service:
   ```bash
   cd services/reverb
   docker compose up --build
   ```

2. Watch startup logs for GPU verification message:
   ```
   [reverb] GPU verified: NVIDIA GeForce RTX ... (XXXX MB)
   ```
   If you see "GPU not available" error, check NVIDIA Container Toolkit installation.

3. Test health endpoint from browser console (F12 -> Console):
   ```javascript
   fetch('http://localhost:8765/health')
     .then(r => r.json())
     .then(console.log)
   ```
   Expected: `{status: "ready", model_loaded: false, gpu: {name: "...", memory_mb: ...}}`

4. If CORS error appears, report the exact error message.

5. (Optional) Test ensemble with a small WAV file if you have one ready.
  </how-to-verify>
  <resume-signal>
Type one of:
- "approved" - Health endpoint accessible from browser, GPU verified
- "cors-error: [message]" - CORS blocking, include error
- "gpu-error: [message]" - GPU not detected, include error
- "build-error: [message]" - Docker build failed, include error
  </resume-signal>
</task>

</tasks>

<verification>
Requirements coverage:
- BACK-01: Docker container with GPU access (verified at startup)
- BACK-02: /ensemble endpoint with v=1.0 and v=0.0
- BACK-03: /health endpoint with status and GPU info
- BACK-04: GPU verification at startup with clear error
- BACK-05: CTM parsing with word timestamps and default confidence

Success Criteria from roadmap:
1. Docker container starts with GPU access verified - startup event
2. /health responds with GPU info from browser - CORS + endpoint
3. /ensemble returns dual transcripts - endpoint implementation
4. 5-minute audio without VRAM - gpu_lock + empty_cache (full test deferred)
5. CORS works - middleware configuration
</verification>

<success_criteria>
1. Docker container builds successfully
2. Container starts with GPU verification message in logs
3. Browser fetch to /health returns JSON with gpu info (no CORS error)
4. server.py contains startup GPU check, health endpoint, CTM parser, ensemble endpoint
5. User confirms browser access works
</success_criteria>

<output>
After completion, create `.planning/phases/20-reverb-backend-service/20-02-SUMMARY.md`
</output>
