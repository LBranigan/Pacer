---
phase: 04-ocr-async-stt
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - js/stt-api.js
  - js/app.js
autonomous: true

must_haves:
  truths:
    - "Audio recordings longer than 55 seconds are routed to async longrunningrecognize"
    - "Async STT polls for completion and returns results in the same format as sync"
    - "If inline audio is rejected by longrunningrecognize, chunked sync fallback processes the audio"
    - "UI shows progress feedback during async processing"
  artifacts:
    - path: "js/stt-api.js"
      provides: "Async STT with polling and chunked fallback"
      exports: ["sendToSTT", "sendToAsyncSTT"]
    - path: "js/app.js"
      provides: "Duration-based routing to sync vs async"
      contains: "sendToAsyncSTT"
  key_links:
    - from: "js/app.js"
      to: "js/stt-api.js"
      via: "processAssessment checks elapsedSeconds > 55"
      pattern: "elapsedSeconds.*55"
    - from: "js/stt-api.js"
      to: "speech.googleapis.com/v1/speech:longrunningrecognize"
      via: "fetch POST for async recognition"
      pattern: "longrunningrecognize"
---

<objective>
Add async STT support for audio recordings longer than 60 seconds via the longrunningrecognize endpoint.

Purpose: The current sync `speech:recognize` endpoint has a ~60 second limit. Longer passages (common in classroom assessments) need the async path. This plan adds duration-based routing, async polling with progress UI, and a chunked-sync fallback if inline audio is rejected.
Output: Modified `js/stt-api.js` with async STT functions, updated `js/app.js` with duration routing.
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ocr-async-stt/04-RESEARCH.md
@.planning/phases/04-ocr-async-stt/04-01-SUMMARY.md
@js/stt-api.js
@js/app.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add async STT with polling and fallback to stt-api.js</name>
  <files>js/stt-api.js</files>
  <action>
Add three new exported functions to `js/stt-api.js` (keep existing `sendToSTT` unchanged):

1. `sendToAsyncSTT(blob, encoding, onProgress)` — Async function that:
   - Gets apiKey from DOM (same pattern as sendToSTT)
   - Converts blob to base64 via existing `blobToBase64`
   - Builds the same config object as sendToSTT (languageCode, model, useEnhanced, enableWordTimeOffsets, enableWordConfidence, maxAlternatives, speechContexts from transcript textarea)
   - POSTs to `https://speech.googleapis.com/v1/speech:longrunningrecognize?key=` with `{ config, audio: { content: base64 } }`
   - If response contains error with message matching "Inline audio" or "GCS URI", throw a specific error with code `INLINE_REJECTED` (e.g., `const err = new Error(msg); err.code = 'INLINE_REJECTED'; throw err;`)
   - Otherwise, call `pollOperation(operation.name, apiKey, onProgress)` and return result
   - Return data in same shape as sync (the `response` field from the completed operation)

2. `pollOperation(operationName, apiKey, onProgress)` — Async function that:
   - Polls `https://speech.googleapis.com/v1/operations/{operationName}?key=` every 3 seconds
   - Calls `onProgress(op.metadata?.progressPercent || 0)` on each poll if onProgress provided
   - Has a 5-minute timeout (100 polls max). If exceeded, throw `new Error('Async STT timed out after 5 minutes')`
   - When `op.done` is true: if `op.error`, throw; otherwise return `op.response`

3. `sendChunkedSTT(blob, encoding)` — Async function that:
   - This is the fallback if longrunningrecognize rejects inline audio
   - Splits the blob into chunks of ~50 seconds each (calculate byte size based on total duration estimate: `blob.size / (duration estimate)` bytes per second, then `50 * bytesPerSec` bytes per chunk)
   - Actually, simpler approach: split the blob by size. For WebM/Opus at ~32kbps, 50s ≈ 200KB. Use 200KB chunks as default. Split blob via `blob.slice(start, end)`.
   - Send each chunk to the existing sync `speech:recognize` endpoint (reuse the fetch logic from sendToSTT but accept base64 directly)
   - Merge results: concatenate all `results` arrays, adjust word timestamps by adding cumulative offset per chunk
   - NOTE: Blob.slice on WebM may not produce valid audio segments. If this is a concern, document it as a known limitation. The primary path is longrunningrecognize with inline content; chunked is best-effort fallback.
   - Return merged data in same shape as sync response

Extract the config-building logic (encoding, languageCode, model, speechContexts, etc.) into a private helper `buildSTTConfig(encoding)` to avoid duplication between sync and async paths.
  </action>
  <verify>
Read js/stt-api.js and verify:
1. `sendToAsyncSTT` is exported and calls longrunningrecognize
2. `pollOperation` polls with 3s interval and 5-min timeout
3. `sendChunkedSTT` is exported as fallback
4. `buildSTTConfig` helper is used by both sync and async
5. No syntax errors (load page, check console)
  </verify>
  <done>stt-api.js exports sendToAsyncSTT, pollOperation, and sendChunkedSTT alongside existing sendToSTT. Config building is DRY.</done>
</task>

<task type="auto">
  <name>Task 2: Wire duration-based routing in app.js with progress UI</name>
  <files>js/app.js</files>
  <action>
Modify `js/app.js`:

1. Import `sendToAsyncSTT` and `sendChunkedSTT` from `./stt-api.js`

2. In `processAssessment(blob, encoding, elapsedSeconds)`, replace the direct `sendToSTT` call with duration-based routing:
   ```javascript
   let data;
   if (elapsedSeconds != null && elapsedSeconds > 55) {
     setStatus('Processing long recording via async STT...');
     try {
       data = await sendToAsyncSTT(blob, encoding, (pct) => {
         setStatus(`Processing long recording... ${pct}%`);
       });
     } catch (err) {
       if (err.code === 'INLINE_REJECTED') {
         setStatus('Async STT unavailable for inline audio. Using chunked processing...');
         data = await sendChunkedSTT(blob, encoding);
       } else {
         setStatus('Async STT error: ' + err.message);
         return;
       }
     }
   } else {
     data = await sendToSTT(blob, encoding);
   }
   ```

3. The rest of processAssessment continues unchanged — it already handles `data` being null or having results.

4. For file uploads via file-handler (which pass `null` for elapsedSeconds): these will always go sync, which is correct since uploaded files are typically short test clips. No change needed.
  </action>
  <verify>
Read js/app.js and verify:
1. sendToAsyncSTT and sendChunkedSTT are imported
2. Duration check at 55 seconds routes to async
3. INLINE_REJECTED error falls back to chunked
4. Progress callback updates status
5. No syntax errors (load page, check console)
  </verify>
  <done>Audio recordings >55s are routed to async STT with progress feedback. If async rejects inline audio, chunked sync fallback is used. Short recordings use existing sync path unchanged.</done>
</task>

</tasks>

<verification>
- stt-api.js exports sendToAsyncSTT, pollOperation, sendChunkedSTT
- app.js routes based on elapsedSeconds > 55
- Progress feedback shown during async polling
- INLINE_REJECTED triggers chunked fallback
- Existing sync path unchanged for short recordings
- No console errors on load
</verification>

<success_criteria>
Audio recordings longer than 55 seconds are processed via async longrunningrecognize with polling progress. If the endpoint rejects inline audio, the app falls back to chunked sync processing. Short recordings continue to use the existing sync endpoint.
</success_criteria>

<output>
After completion, create `.planning/phases/04-ocr-async-stt/04-02-SUMMARY.md`
</output>
