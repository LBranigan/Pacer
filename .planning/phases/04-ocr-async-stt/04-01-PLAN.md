---
phase: 04-ocr-async-stt
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - js/ocr-api.js
  - index.html
  - js/app.js
  - sw.js
autonomous: false

must_haves:
  truths:
    - "Teacher can photograph or upload a book page image"
    - "App extracts readable text from the image via Google Vision OCR"
    - "Extracted OCR text appears in an editable textarea for review"
    - "Teacher can edit OCR text and use it as the reference passage"
  artifacts:
    - path: "js/ocr-api.js"
      provides: "Image resize and Vision OCR API call"
      exports: ["extractTextFromImage"]
    - path: "index.html"
      provides: "Image upload input and OCR preview/edit UI"
      contains: "imageInput"
  key_links:
    - from: "index.html"
      to: "js/ocr-api.js"
      via: "app.js wiring image input change event"
      pattern: "extractTextFromImage"
    - from: "js/ocr-api.js"
      to: "vision.googleapis.com"
      via: "fetch POST to images:annotate"
      pattern: "vision.googleapis.com"
---

<objective>
Add Google Vision OCR so teachers can photograph a book page and extract text as the reference passage.

Purpose: Teachers currently must type/paste reference text manually. OCR lets them snap a photo of any book page, review the extracted text, edit if needed, and use it directly.
Output: New `js/ocr-api.js` module, updated `index.html` with image upload UI and OCR preview, wiring in `js/app.js`.
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ocr-async-stt/04-RESEARCH.md
@index.html
@js/stt-api.js
@js/app.js
@sw.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create OCR API module and image upload UI</name>
  <files>js/ocr-api.js, index.html, js/app.js, sw.js</files>
  <action>
Create `js/ocr-api.js` with two exported functions:

1. `resizeImageIfNeeded(file, maxDimension = 2048)` â€” Returns a Promise resolving to a Blob. Uses Canvas API to resize images where either dimension exceeds maxDimension. Preserves aspect ratio. Outputs JPEG at 0.85 quality. If image is already small enough, resolves with the original file.

2. `extractTextFromImage(file, apiKey)` â€” Async function that:
   - Calls resizeImageIfNeeded on the file
   - Converts result to base64 via FileReader.readAsDataURL, strips the `data:...;base64,` prefix
   - POSTs to `https://vision.googleapis.com/v1/images:annotate?key=` with body: `{ requests: [{ image: { content: base64 }, features: [{ type: 'DOCUMENT_TEXT_DETECTION' }] }] }`
   - Checks `data.responses[0]?.error` and throws if present
   - Returns `data.responses[0]?.fullTextAnnotation?.text || ''`

In `index.html`, add a new section BETWEEN the API key section and the Reference Passage section:

```html
<div class="section">
  <label>Book Page OCR (optional)</label>
  <div class="controls">
    <label id="ocrUploadBtn" style="background:#388e3c;color:#fff;padding:0.6rem 1.4rem;border-radius:4px;font-weight:600;cursor:pointer;">
      ðŸ“· Photograph / Upload Page
      <input type="file" id="imageInput" accept="image/*" capture="environment" style="display:none">
    </label>
  </div>
  <div id="ocrPreview" style="display:none; margin-top:0.5rem;">
    <img id="ocrImage" style="max-width:100%; max-height:200px; border-radius:4px; margin-bottom:0.5rem;">
    <textarea id="ocrText" rows="6" placeholder="OCR text will appear here for review..."></textarea>
    <button id="useOcrBtn" style="margin-top:0.5rem; background:#1976d2; color:#fff; padding:0.5rem 1rem; border:none; border-radius:4px; cursor:pointer; font-weight:600;">Use as Reference Passage</button>
  </div>
  <div id="ocrStatus"></div>
</div>
```

In `js/app.js`:
- Import `extractTextFromImage` from `./ocr-api.js`
- After `initFileHandler()` and the callback wiring, add OCR wiring:
  - Get `imageInput`, `ocrPreview`, `ocrImage`, `ocrText`, `ocrStatus`, `useOcrBtn` elements
  - On `imageInput` change: show ocrPreview, display image thumbnail via `URL.createObjectURL`, set ocrStatus to "Extracting text...", call `extractTextFromImage(file, apiKey)`, put result in ocrText textarea, update ocrStatus to "Text extracted â€” review and edit, then click 'Use as Reference Passage'". On error, show error in ocrStatus.
  - On `useOcrBtn` click: copy ocrText.value into the `transcript` textarea (the existing reference passage field), ocrStatus = "Reference passage updated."

In `sw.js`:
- Add `'./js/ocr-api.js'` to the SHELL array
- Bump CACHE_NAME to `'orf-v2'`
  </action>
  <verify>
Open index.html in browser. Verify:
1. Image upload button appears between API key and Reference Passage sections
2. Selecting an image shows the preview thumbnail and triggers OCR (with valid API key)
3. OCR text appears in editable textarea
4. "Use as Reference Passage" copies text to the main transcript textarea
5. No console errors on page load
  </verify>
  <done>Teacher can upload/photograph a book page, see extracted text, edit it, and use it as reference passage. OCR preview section shows image thumbnail. Service worker caches the new module.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>OCR image upload with Google Vision text extraction, editable preview, and "Use as Reference Passage" button</what-built>
  <how-to-verify>
    1. Open the app in browser
    2. Enter a valid Google Cloud API key (must have Vision API enabled)
    3. Click "Photograph / Upload Page" and select a photo of a book page
    4. Verify: image thumbnail appears, OCR text appears in editable textarea
    5. Edit the OCR text if needed
    6. Click "Use as Reference Passage"
    7. Verify: text appears in the main Reference Passage textarea
    8. Test on mobile if possible: camera capture should open
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
- `js/ocr-api.js` exists and exports `extractTextFromImage`
- Image input element exists in index.html with `accept="image/*" capture="environment"`
- OCR preview section with editable textarea and "Use" button exists
- app.js imports and wires OCR functionality
- sw.js includes ocr-api.js in SHELL and has updated cache version
- No console errors on load
</verification>

<success_criteria>
Teacher can photograph or upload a book page image, review and edit extracted OCR text, and use it as the reference passage for assessment.
</success_criteria>

<output>
After completion, create `.planning/phases/04-ocr-async-stt/04-01-SUMMARY.md`
</output>
