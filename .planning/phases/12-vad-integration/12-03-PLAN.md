---
phase: 12-vad-integration
plan: 03
type: execute
wave: 3
depends_on: ["12-01", "12-02"]
files_modified:
  - js/app.js
  - index.html
autonomous: true

must_haves:
  truths:
    - "VAD processes completed audio during 'Processing...' spinner phase"
    - "Ghost detection runs on ensemble-merged words before alignment"
    - "Ghost count appears in assessment metrics"
    - "Saved assessments include _vad field with ghost detection results"
    - "VAD failure shows warning but assessment continues"
  artifacts:
    - path: "js/app.js"
      provides: "VAD integration in runAnalysis flow"
      contains: "vadProcessor.processAudio"
  key_links:
    - from: "js/app.js"
      to: "js/vad-processor.js"
      via: "import vadProcessor"
      pattern: "import.*vadProcessor.*from.*vad-processor"
    - from: "js/app.js"
      to: "js/ghost-detector.js"
      via: "import flagGhostWords"
      pattern: "import.*flagGhostWords.*from.*ghost-detector"
---

<objective>
Integrate VAD and ghost detection into the main assessment flow in app.js.

Purpose: This connects the VAD foundation (Plan 01) and ghost detection logic (Plan 02) into the actual assessment workflow. After this plan, ghost words will be flagged in real assessments and the data will be preserved for UI display (Phase 16).

Output: Updated `js/app.js` with VAD integration in runAnalysis flow
</objective>

<execution_context>
@/home/brani/.claude/get-shit-done/workflows/execute-plan.md
@/home/brani/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-vad-integration/12-CONTEXT.md
@.planning/phases/12-vad-integration/12-RESEARCH.md

# Prior plans
@.planning/phases/12-vad-integration/12-01-PLAN.md
@.planning/phases/12-vad-integration/12-02-PLAN.md

# Source files to modify
@js/app.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add VAD imports and initialization to app.js</name>
  <files>js/app.js</files>
  <action>
Add imports at the top of app.js with other imports:

```javascript
import { vadProcessor } from './vad-processor.js';
import { flagGhostWords } from './ghost-detector.js';
```

After the initRecorder() and initFileHandler() calls (around line 545-546), add VAD initialization:

```javascript
// Initialize VAD for ghost detection (Phase 12)
vadProcessor.init().then(() => {
  if (vadProcessor.isLoaded) {
    console.log('[ORF] VAD initialized for ghost detection');
  } else {
    console.warn('[ORF] VAD failed to load:', vadProcessor.loadError);
  }
});
```

This pre-loads the ONNX model so it's ready when recordings are analyzed.
  </action>
  <verify>Load page, check console for "[ORF] VAD initialized for ghost detection" message</verify>
  <done>VAD imports added, initialization runs on page load</done>
</task>

<task type="auto">
  <name>Task 2: Integrate VAD processing into sync assessment flow</name>
  <files>js/app.js</files>
  <action>
Modify the runAnalysis() function to include VAD processing. The VAD should run in parallel with or just after the STT call, during the "Processing..." phase.

Find the sync path section (around line 122-167, inside the else block after checking elapsedSeconds > 55). After the ensemble merge and stats computation, add VAD processing:

```javascript
// After this existing code (around line 143-152):
// const mergedWords = mergeEnsembleResults(ensembleResult);
// const ensembleStats = computeEnsembleStats(mergedWords);

// Add VAD processing for ghost detection (Phase 12)
let vadResult = { segments: [], durationMs: 0, error: 'VAD not initialized' };
let ghostResult = { ghostCount: 0, hasGhostSequence: false, vadError: null };

if (vadProcessor.isLoaded) {
  setStatus('Running ghost detection...');
  vadResult = await vadProcessor.processAudio(appState.audioBlob);

  addStage('vad_processing', {
    segmentCount: vadResult.segments.length,
    durationMs: vadResult.durationMs,
    error: vadResult.error
  });

  // Run ghost detection on merged words
  const referenceText = document.getElementById('transcript').value.trim();
  ghostResult = flagGhostWords(mergedWords, vadResult, referenceText, vadResult.durationMs);

  addStage('ghost_detection', {
    ghostCount: ghostResult.ghostCount,
    hasGhostSequence: ghostResult.hasGhostSequence,
    vadError: ghostResult.vadError,
    ghostIndices: ghostResult.ghostIndices
  });

  if (ghostResult.ghostCount > 0) {
    console.log(`[ORF] Ghost detection: ${ghostResult.ghostCount} potential hallucinations flagged`);
  }
} else {
  addWarning('VAD not loaded', { error: vadProcessor.loadError });
  console.warn('[ORF] VAD not loaded, skipping ghost detection:', vadProcessor.loadError);
}
```

Then update the data object construction (around line 155-167) to include VAD data:

```javascript
data = {
  results: [{
    alternatives: [{
      words: mergedWords,
      transcript: mergedWords.map(w => w.word).join(' ')
    }]
  }],
  _ensemble: {
    raw: ensembleResult,
    stats: ensembleStats
  },
  _vad: {
    segments: vadResult.segments,
    durationMs: vadResult.durationMs,
    ghostCount: ghostResult.ghostCount,
    hasGhostSequence: ghostResult.hasGhostSequence,
    error: vadResult.error || ghostResult.vadError
  }
};
```
  </action>
  <verify>Record audio with speech and silence, analyze. Check debug log has vad_processing and ghost_detection stages. Check console for ghost detection message if any flagged.</verify>
  <done>VAD processing runs during assessment, ghost detection flags latest_only words with no speech overlap</done>
</task>

<task type="auto">
  <name>Task 3: Preserve VAD data in saved assessments and update version</name>
  <files>js/app.js, index.html</files>
  <action>
In the saveAssessment call (around line 496-510), add the _vad field:

```javascript
saveAssessment(appState.selectedStudentId, {
  _id: assessmentId,
  wcpm: wcpm ? wcpm.wcpm : null,
  accuracy: accuracy.accuracy,
  totalWords: accuracy.totalRefWords,
  errors: accuracy.substitutions + accuracy.omissions,
  duration: effectiveElapsedSeconds,
  passagePreview: referenceText.slice(0, 60),
  errorBreakdown,
  alignment,
  sttWords: transcriptWords,
  audioRef: appState.audioBlob ? assessmentId : null,
  nlAnnotations,
  _ensemble: data._ensemble || null,
  _vad: data._vad || null  // Add VAD ghost detection data
});
```

Also add ghost count to the finalizeDebugLog call (around line 520-528):

```javascript
finalizeDebugLog({
  studentId: appState.selectedStudentId,
  assessmentId,
  wcpm: wcpm?.wcpm || null,
  accuracy: accuracy.accuracy,
  totalWords: accuracy.totalRefWords,
  errors: accuracy.substitutions + accuracy.omissions,
  forgiven: accuracy.forgiven,
  ghostCount: data._vad?.ghostCount || 0  // Add ghost count
});
```

Finally, update the version timestamp in index.html #version element and the CODE_VERSION constant in app.js.
  </action>
  <verify>Run assessment with a student selected. Check localStorage for saved assessment, verify _vad field exists with ghostCount.</verify>
  <done>Saved assessments include _vad data with ghost detection results, debug log includes ghostCount</done>
</task>

</tasks>

<verification>
1. Load page, verify VAD initialization message in console
2. Record a short audio clip (5-10 seconds) with clear speech
3. Add reference text matching what you said
4. Click Analyze
5. Check debug log (if debug mode enabled) for vad_processing and ghost_detection stages
6. Check that assessment completes successfully
7. If any ghosts flagged, verify they are latest_only words
8. Check saved assessment in localStorage has _vad field
</verification>

<success_criteria>
- [x] VAD initializes on page load (console message)
- [x] VAD processes audio during "Processing..." phase
- [x] Ghost detection runs on merged words
- [x] Ghost count logged to console when > 0
- [x] Debug log includes vad_processing and ghost_detection stages
- [x] Saved assessments have _vad field with ghostCount, hasGhostSequence, error
- [x] VAD failure shows warning in console but assessment continues
- [x] Version timestamp updated
</success_criteria>

<output>
After completion, create `.planning/phases/12-vad-integration/12-03-SUMMARY.md`
</output>
